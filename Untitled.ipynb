{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f66788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d49e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"creditcard.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a4a042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19deda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf25d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8258544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid transaction 284315\n",
      "fraud transaction 492\n"
     ]
    }
   ],
   "source": [
    "print('Valid transaction',len(data[data['Class']==0]))\n",
    "print('fraud transaction',len(data[data['Class']==1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb0de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= data['Class']\n",
    "x= data.drop(columns=['Class'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0189482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size= 0.3,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa1d0c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting randomforest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7360ce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, n_estimators=20,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, n_estimators=20,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=20,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_1\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=20,criterion='entropy', random_state=0,max_depth=10)\n",
    "classifier.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a99fdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, n_estimators=20,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, n_estimators=20,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=20,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=20,\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b5287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17b14771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.95      0.76      0.85       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.88      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Confusion matrix:\n",
      " [[85290     6]\n",
      " [   35   112]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report, confusion_matrix\n",
    "print('Classifcation report:\\n', classification_report(y_test, y_pred))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print('Confusion matrix:\\n', conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76362c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, n_estimators=30,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, n_estimators=30,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=30,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=30,criterion='entropy', random_state=0,max_depth=10)\n",
    "classifier.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb41ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, n_estimators=30,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, n_estimators=30,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=30,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=30,\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a070788",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = classifier.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49e6c099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.95      0.78      0.86       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.89      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Confusion matrix:\n",
      " [[85290     6]\n",
      " [   32   115]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report, confusion_matrix\n",
    "print('Classifcation report:\\n', classification_report(y_test, y_pred_2))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred_2)\n",
    "print('Confusion matrix:\\n', conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbb9cd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85296\n",
      "           1       0.07      0.90      0.13       147\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.54      0.94      0.56     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n",
      "Confusion matrix:\n",
      " [[83592  1704]\n",
      " [   15   132]]\n"
     ]
    }
   ],
   "source": [
    "#trying with undersmapling technique\n",
    "# This is the pipeline module we need from imblearn for Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "# Define which resampling method and which ML model to use in the pipeline\n",
    "resampling = RandomUnderSampler()\n",
    "model = RandomForestClassifier(n_estimators=30,criterion='entropy', random_state=0,max_depth=10)\n",
    "\n",
    "\n",
    "# Define the pipeline and combine sampling method with the RF model\n",
    "pipeline = Pipeline([('RandomUnderSampler', resampling), ('RF', model)])\n",
    "pipeline.fit(x_train, y_train) \n",
    "predicted = pipeline.predict(x_test)\n",
    "\n",
    "\n",
    "# Obtain the results from the classification report and confusion matrix \n",
    "print('Classifcation report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c32a09b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.85      0.81      0.83       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.92      0.90      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Confusion matrix:\n",
      " [[85275    21]\n",
      " [   28   119]]\n"
     ]
    }
   ],
   "source": [
    "# This is the pipeline module we need from imblearn for Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Define which resampling method and which ML model to use in the pipeline\n",
    "resampling = RandomOverSampler()\n",
    "model = RandomForestClassifier(n_estimators=30,criterion='entropy', random_state=0,max_depth=10)\n",
    "\n",
    "# Define the pipeline and combine sampling method with the model\n",
    "pipeline = Pipeline([('RandomOverSampler', resampling), ('RF', model)])\n",
    "pipeline.fit(x_train, y_train) \n",
    "predicted = pipeline.predict(x_test)\n",
    "\n",
    "\n",
    "# Obtain the results from the classification report and confusion matrix \n",
    "print('Classifcation report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb7a3164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.66      0.85      0.74       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.83      0.92      0.87     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Confusion matrix:\n",
      " [[85232    64]\n",
      " [   22   125]]\n"
     ]
    }
   ],
   "source": [
    "# This is the pipeline module we need from imblearn for SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Define which resampling method and which ML model to use in the pipeline\n",
    "resampling = SMOTE(sampling_strategy='auto',random_state=0)\n",
    "model = RandomForestClassifier(n_estimators=30,criterion='entropy', random_state=0,max_depth=10)\n",
    "\n",
    "# Define the pipeline and combine sampling method with the model\n",
    "pipeline = Pipeline([('SMOTE', resampling), ('RF', model)])\n",
    "pipeline.fit(x_train, y_train) \n",
    "predicted = pipeline.predict(x_test)\n",
    "\n",
    "\n",
    "# Obtain the results from the classification report and confusion matrix \n",
    "print('Classifcation report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c46d7f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c40523a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visulalizing the confusion matrix\n",
    "LABELS = ['Normal', 'Fraud'] \n",
    "conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "plt.figure(figsize =(12, 12)) \n",
    "sns.heatmap(conf_matrix, xticklabels = LABELS, yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
    "plt.title(\"Confusion matrix\") \n",
    "plt.ylabel('True class') \n",
    "plt.xlabel('Predicted class') \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d66f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9a396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c00994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79277a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e3f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e3a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd65c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e52c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93bec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
